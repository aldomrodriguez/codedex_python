
![T√≠tulo Imagen](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png)

**Requisitos previos:** Fundamentos de python  
**Versiones:** Python 3.10, python-dotenv 0.21.0, openai 1.0.0  
**Tiempo de Lectura:** 60 Minutos

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#introduction) Introducci√≥n

[Inteligencia Artificial (IA)](https://en.wikipedia.org/wiki/Artificial_intelligence) se est√° convirtiendo en la pr√≥xima gran tecnolog√≠a para aprovechar. Desde refrigeradores inteligentes hasta autos sin conductor, la IA se implementa en casi todo lo que se te ocurra. As√≠ que adelant√©monos y aprendamos c√≥mo podemos aprovechar el poder de la IA con Python y OpenAI.

En este tutorial, aprenderemos c√≥mo crear un generador de blogs con [GPT-3](https://openai.com/api/), un modelo de IA proporcionado por [OpenAI](https://www.openai.com/). El generador leer√° un tema para hablar como la entrada, y GPT-3 nos devolver√° un p√°rrafo sobre ese tema como la salida.

Entonces AI estar√° "escribiendo" cosas para nosotros. ¬°Diga adi√≥s al bloque del escritor!

¬°Pero espera, espera! ¬°Inteligencia artificial?! ¬°Modelos de IA?! Esto debe ser complicado de codificar. üòµ

![meme](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/calculation-math.gif)

No, es m√°s f√°cil de lo que piensas. ¬°Se necesitan alrededor de 25 l√≠neas de c√≥digo Python!

El resultado final se ver√° as√≠:

![demo del generador](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/generator-demo.gif)

_Qui√©n sabe, tal vez todo este proyecto fue escrito por el generador que estamos a punto de crear. üëÄ_

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#what-is-gpt-3) ¬øQu√© es GPT-3?

[GPT-3](https://en.wikipedia.org/wiki/GPT-3) es un modelo de IA lanzado por OpenAI en 2020. Un modelo de IA es un programa entrenado en un mont√≥n de datos para realizar una tarea espec√≠fica. En este caso, GPT-3 fue entrenado para hablar como un ser humano y predecir lo que viene despu√©s dado el contexto de una oraci√≥n, con su conjunto de datos de entrenamiento de 45 terabytes de texto (!) de internet.

> Como referencia, si tuviera que seguir escribiendo hasta que su papel alcance los 45 terabytes de tama√±o, tendr√≠a que escribir [22.500.000.000](https://www.techtarget.com/searchstorage/definition/How-many-bytes-for) p√°ginas de texto sin formato.

Dado que GPT-3 fue entrenado en datos de Internet, sabe lo que Internet sabe (no todo, por supuesto). Esto significa que si tuvi√©ramos que dar GPT-3 una oraci√≥n, ser√≠a capaz de predecir lo que viene despu√©s en esa oraci√≥n con alta precisi√≥n, en base a todo el texto que se utiliz√≥ para entrenarla.

Ahora sabemos con qu√© trabajaremos, ¬°construyamos el programa!

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#setting-up) Configuraci√≥n

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#openai-account) Cuenta OpenAI

Antes de hacer algo, necesitamos un [OpenAI](https://openai.com/api) cuenta. Necesitaremos esto para acceder a una clave API para usar GPT-3. Tenga en cuenta que OpenAI ya no ofrece cr√©ditos gratuitos, por lo que deber√° comprar al menos 5 d√≥lares en cr√©ditos para comenzar a usar la API.

> [API (Interfaz de Programaci√≥n de Aplicaciones)](https://en.wikipedia.org/wiki/API) es una forma para que dos computadoras se comuniquen entre s√≠. Piense en ello como dos amigos enviando mensajes de texto de un lado a otro. Una clave API es un c√≥digo que recibimos para acceder a la API. Piense en ello como una contrase√±a importante, ¬°as√≠ que no la comparta con otros!

Ir a [www.en.com](http://www.openai.com/) y reg√≠strese para obtener una cuenta OpenAI.

Despu√©s de crear una cuenta, haga clic en la imagen de su perfil en la parte superior derecha, luego haga clic en "Ver claves API" para acceder a su clave API. Deber√≠as ver [esta p√°gina](https://beta.openai.com/account/api-keys) y deber√≠a verse como:

![Clave API](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/api-key.png)

Ahora que sabemos d√≥nde se encuentra la clave API, tengamos en cuenta para m√°s adelante.

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#python-setup) Configuraci√≥n de Python

Para este proyecto, necesitaremos [Python 3](https://www.python.org/downloads/) y [pip](https://pip.pypa.io/en/stable/) (instalador de paquetes) instalado.

Suponiendo que tenemos esos dos instalados, abramos el editor de c√≥digo de nuestra elecci√≥n (recomendamos [c√≥digo VS](https://code.visualstudio.com/)) y crear un nuevo archivo llamado **blog\_generador.py**.

**Nota**: Puede nombrar este archivo cualquier cosa excepto **openai.p**, ya que el nombre chocar√° con un paquete que instalaremos.

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#beginning-the-project) Comenzando el Proyecto

En el centro de este proyecto, todo lo que haremos es enviar datos con instrucciones a un servidor propiedad de OpenAI, luego recibir una respuesta de ese servidor y mostrarla.

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#install-openai) Instalar openai

Interactuaremos con el modelo GPT-3 usando un paquete python llamado `openai`. Este paquete consta de m√©todos que pueden conectarse a Internet y otorgarnos acceso al modelo GPT-3 alojado por OpenAI, la empresa.

Para instalar `openai`, todo lo que tenemos que hacer es ejecutar el siguiente comando en nuestro terminal:

    pip install openai
    

Ahora podemos usar este paquete import√°ndolo a nuestro **blog\_generador.py** archivo como as√≠:

    import openai
    

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#authorize-api-key) Autorizar API Key

Antes de que podamos trabajar con GPT-3, debemos establecer nuestra clave API en el `openai` m√≥dulo. Recuerde, la clave API es lo que nos da acceso a GPT-3; nos autoriza y dice que se nos permite usar esta API.

Podemos establecer nuestra clave API extendiendo un m√©todo en el `openai` m√≥dulo llamado `api_key`:

    openai.api_key = 'Your_API_Key'
    

El m√©todo tomar√° la clave API como una cadena. Recuerde, su clave API se encuentra en su [Cuenta openAI](https://beta.openai.com/account/api-keys).

Hasta ahora, el c√≥digo deber√≠a verse as√≠:

    import openai
    
    openai.api_key = 'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk' # Fill in your own key
    

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#the-core-function) La Funci√≥n Central

Ahora que tenemos acceso a GPT-3, podemos llegar a la carne de la aplicaci√≥n, que est√° creando una funci√≥n que toma un mensaje como entrada del usuario y devuelve un p√°rrafo sobre ese mensaje.

Esa funci√≥n se ver√° as√≠:

    def generate_blog(paragraph_topic):
      response = openai.completions.create(
        model = 'gpt-3.5-turbo-instruct',
        prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,
        max_tokens = 400,
        temperature = 0.3
      )
    
      retrieve_blog = response.choices[0].text
    
      return retrieve_blog
    

Desglosemos esta funci√≥n y veamos qu√© est√° pasando aqu√≠.

Primero, definimos una funci√≥n llamada `generate_blog()`. Hay un solo par√°metro llamado `paragraph_topic`, que ser√° el tema utilizado para generar el p√°rrafo:

    def generate_blog(paragraph_topic):
      # The code inside
    

Y entremos en la funci√≥n. Aqu√≠ est√° la primera parte:

    def generate_blog(paragraph_topic):
      response = openai.completions.create(
        model = 'gpt-3.5-turbo-instruct',
        prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,
        max_tokens = 400,
        temperature = 0.3
      )
    

Esta es la mayor parte de nuestra funci√≥n y donde usamos GPT-3. Creamos una variable llamada `response` para almacenar la respuesta generada por la salida de la `completions.create()` llamada de m√©todo en nuestro `openai` m√≥dulo.

GPT-3 tiene diferentes puntos finales para prop√≥sitos espec√≠ficos, pero para nuestro objetivo, usaremos el [finalizaci√≥n](https://beta.openai.com/docs/api-reference/completions) punto final. El punto final de finalizaci√≥n generar√° texto dependiendo del mensaje proporcionado. Puede leer sobre los diferentes puntos finales en el [documentaci√≥n](https://beta.openai.com/docs/introduction).

Ahora que tenemos acceso al punto final de finalizaci√≥n, debemos especificar algunas cosas, la primera es:

`model`: El par√°metro del modelo tomar√° en el modelo que queremos utilizar. OpenAI ofrece varios modelos con diferentes capacidades. Para este tutorial, estamos usando `gpt-3.5-turbo-instruct` para proporcionar ejemplos claros y confiables.

La sintaxis y las capacidades var√≠an entre los modelos. Puede leer m√°s sobre los modelos disponibles en el [documentaci√≥n](https://platform.openai.com/docs/models).

    prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,
    

`prompt`: Aqu√≠ es donde dise√±amos las instrucciones principales para GPT-3. Este par√°metro tomar√° en nuestro `paragraph_topic` argumento, pero antes de eso, podemos decirle a GPT-3 qu√© hacer con ese argumento. Actualmente, estamos instruyendo a GPT-3 a `Write a paragraph about the following topic`. GPT-3 har√° todo lo posible para seguir esta instrucci√≥n y devolvernos un p√°rrafo.

GPT-3 es muy flexible; si la cadena inicial se cambia a `Write a blog outline about the following topic`√©ste nos dar√° un esquema en lugar de un p√°rrafo normal. M√°s tarde puede jugar con esto dici√©ndole al modelo exactamente lo que deber√≠a generar y viendo qu√© respuestas interesantes obtiene.

    max_tokens = 400
    

`tokens`: El n√∫mero de token decide cu√°nto tiempo ser√° la respuesta. Un n√∫mero de token m√°s grande producir√° una respuesta m√°s larga. Al establecer un n√∫mero espec√≠fico, estamos diciendo que la respuesta no puede superar este tama√±o de token. La forma en que se cuentan los tokens para una respuesta es un poco compleja, pero puede leer esto [art√≠culo](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) por OpenAI que explica c√≥mo se calcula el tama√±o del token.

Aproximadamente 75 palabras son aproximadamente 100 fichas. Un p√°rrafo tiene 300 palabras en promedio. Entonces, 400 tokens tienen aproximadamente la longitud de un p√°rrafo normal. El modelo `gpt-3.5-turbo-instruct` tiene un l√≠mite de token de 4.096.

    temperature = 0.3
    

`temperature`: La temperatura determina la aleatoriedad de una respuesta. Una temperatura m√°s alta producir√° una respuesta m√°s creativa, mientras que una temperatura m√°s baja producir√° una respuesta mejor definida.

-   `0`: La misma respuesta cada vez.
-   `1`: Una respuesta diferente cada vez, incluso si es el mismo mensaje.

Hay muchos otros campos que podemos especificar para ajustar a√∫n m√°s el modelo, que puede leer en el [documentaci√≥n](https://beta.openai.com/docs/api-reference/completions/create), pero por ahora, estos son los cuatro campos con los que debemos preocuparnos.

Ahora que tenemos nuestra configuraci√≥n de modelo, podemos ejecutar nuestra funci√≥n y suceder√°n las siguientes cosas:

1.  Primero, el `openai` el m√≥dulo tomar√° nuestra clave API, junto con los campos que especificamos en el `response` variable, y hacer una solicitud al punto final de finalizaci√≥n.
2.  OpenAI verificar√° que se nos permite usar GPT-3 verificando nuestra clave API.
3.  Despu√©s de la verificaci√≥n, GPT-3 utilizar√° los campos especificados para producir una respuesta.
4.  La respuesta producida se devolver√° en forma de un objeto y se almacenar√° en el `response` variable.

Ese objeto devuelto se ver√° as√≠:

    {
      "choices": [
        {
          "finish_reason": "stop",
          "index": 0,
          "logprobs": null,
          "text": "\n\nPython is a programming language with many features, such as an intuitive syntax and powerful data structures. It was created in the late 1980s by Guido van Rossum, with the goal of providing a simple yet powerful scripting language. Python has since become one of the most popular programming languages, with a wide range of applications in fields such as web development, scientific computing, and artificial intelligence."
        }
      ],
      "created": 1664302504,
      "id": "cmpl-5v9OiMOjRyoyypRQWAdpyAtjtgVev",
      "model": "gpt-3.5-turbo-instruct",
      "object": "text_completion",
      "usage": {
        "completion_tokens": 80,
        "prompt_tokens": 19,
        "total_tokens": 99
      }
    }
    

Weirre proporcion√≥ toneladas de informaci√≥n sobre la respuesta, pero lo √∫nico que nos importa es la `text` campo que contiene texto generado.

Podemos acceder al valor en el `text` campo como as√≠:

    retrieve_blog = response.choices[0].text
    

Finalmente, devolvemos el `retrieve_blog` variable que contiene el p√°rrafo que acabamos de sacar del diccionario.

    return retrieve_blog
    

¬°Whoah! Tomemos un momento y respiremos. Eso fue mucho lo que acabamos de cubrir. Vamos a darnos una palmadita en la espalda, ya que hemos terminado en un 90% con la aplicaci√≥n.

Podemos probar para ver si nuestro c√≥digo funciona hasta ahora imprimiendo el `generate_blog()` funci√≥n que acabamos de crear, d√°ndole un tema sobre el que escribir y viendo la respuesta que recibimos.

    print(generate_blog('Why NYC is better than your city.'))
    

Aqu√≠ est√° el c√≥digo completo hasta ahora:

    import openai
    
    openai.api_key = 'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk' # Fill in your own key
    
    def generate_blog(paragraph_topic):
      response = openai.completions.create(
        model = 'gpt-3.5-turbo-instruct',
        prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,
        max_tokens = 400,
        temperature = 0.3
      )
    
      retrieve_blog = response.choices[0].text
    
      return retrieve_blog
    
    print(generate_blog('Why NYC is better than your city.'))
    

Y boom, despu√©s de 2-3 segundos, deber√≠a escupir un p√°rrafo como este:

![Salida: NYC](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/output-nyc.png)

Intenta ejecutar el c√≥digo un par de veces m√°s; ¬°la salida debe ser diferente cada vez! ü§Ø

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#multiple-paragraphs) P√°rrafos M√∫ltiples

En este momento, si ejecutamos nuestro c√≥digo, solo podremos generar un p√°rrafo de texto. Recuerde, estamos tratando de crear un generador de blogs, y un blog tiene m√∫ltiples secciones, con cada p√°rrafo teniendo un tema diferente.

Agreguemos alg√∫n c√≥digo adicional para generar tantos p√°rrafos como queramos, con cada p√°rrafo discutiendo un tema diferente:

    keep_writing = True
    
    while keep_writing:
      answer = input('Write a paragraph? Y for yes, anything else for no. ')
      if (answer == 'Y'):
        paragraph_topic = input('What should this paragraph talk about? ')
        print(generate_blog(paragraph_topic))
      else:
        keep_writing = False
    

Primero, definimos una variable llamada `keep_writing`, para usar como un valor booleano para lo siguiente `while` bucle.

En el `while` loop, creamos un `answer` variable que tomar√° una entrada del usuario utilizando el incorporado `input()` funci√≥n.

Luego creamos un `if` declaraci√≥n que continuar√° el bucle o detendr√° el bucle.

-   Si la entrada del usuario es `Y`, luego le preguntaremos al usuario sobre qu√© tema desea generar texto, almacenando ese valor en una variable llamada `paragraph_topic`. Luego ejecutaremos e imprimiremos el `generate_blog()` funci√≥n usando el `parapgraph_topic` variable como argumento.
-   De lo contrario, detendremos el bucle asignando el `keep_writing` variable a `False`.

¬°Con eso completo, ahora podemos escribir tantos p√°rrafos como queramos ejecutando el programa una vez!

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#rate-limit) L√≠mite de Tasa

Ya que estamos usando un `while` loop, tenemos el potencial de ser limitado en la tasa.

> [L√≠mite de tasa](https://en.wikipedia.org/wiki/Rate_limiting) es el n√∫mero de llamadas API que una aplicaci√≥n o usuario puede hacer dentro de un per√≠odo de tiempo determinado.

Esto normalmente se hace para proteger la API del abuso o [DoS](https://en.wikipedia.org/wiki/Denial-of-service_attack) ataques.

Para GPT-3, el l√≠mite de tasa es de 20 solicitudes por minuto. Mientras no ejecutemos la funci√≥n tan r√°pido, estaremos bien. Pero en un raro caso de que ocurra, GPT-3 dejar√° de producir respuestas y nos har√° esperar un minuto para producir otra respuesta.

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#credit-limit) L√≠mite de Cr√©dito

En este punto, si ha estado jugando con la API sin parar, existe la posibilidad de que haya excedido su l√≠mite de cr√©dito comprado. El siguiente error se lanza cuando eso sucede:

    openai.error.RateLimitError:  
    You exceeded your current quota, please check your plan and billing details.
    

Si ese es el caso, ve a OpenAI's [Resumen de facturaci√≥n](https://platform.openai.com/settings/organization/billing/overview) p√°gina y compra cr√©ditos adicionales.

Tomemos otro respiro. ¬°Ya casi terminamos!

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#securing-our-app) Asegurando Nuestra App

Pensemos en esto por un minuto. Creamos esta incre√≠ble aplicaci√≥n y queremos compartirla con el mundo, ¬øverdad? Bueno, cuando lo implementamos en la web o lo compartimos con nuestros amigos, podr√°n ver cada pieza de c√≥digo en el programa. ¬°Ah√≠ es donde radica el problema!

Al comienzo de este art√≠culo, creamos una cuenta con OpenAI y se nos asign√≥ una clave API. Recuerde, esta clave API es lo que nos da acceso a GPT-3. Dado que GPT-3 es un servicio de pago, la clave API tambi√©n se utiliza para rastrear el uso y cobrarnos en consecuencia. Entonces, ¬øqu√© sucede cuando alguien conoce nuestra clave API? Podr√°n usar el servicio con nuestra llave, y seremos los que cobramos, ¬°potencialmente miles de d√≥lares!

Para protegernos, necesitamos ocultar la clave API en nuestro c√≥digo pero a√∫n as√≠ poder usarla. Veamos c√≥mo podemos hacer eso.

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#install-python-dotenv) Instalar `python-dotenv`

[`python-dotenv`](https://pypi.org/project/python-dotenv)es un paquete que nos permite crear y utilizar variables de entorno sin tener que configurarlas manualmente en el sistema operativo.

> Las variables de entorno son variables cuyos valores se establecen fuera del programa, generalmente en el sistema operativo.

Podemos instalar `python-dotenv` ejecutando el siguiente comando en el terminal:

    pip install python-dotenv
    

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#env-file) Archivo .env

Luego, en el directorio ra√≠z de nuestro proyecto, cree un archivo llamado **.env**. Este archivo mantendr√° nuestra variable de entorno.

Abre el **.env** archiva y crea una variable como as√≠:

    API_KEY=<Your_API_Key>
    

La variable incluir√° nuestra clave API sin comillas ni espacios. Recuerde nombrar esta variable como `API_KEY` s√≥lo.

### [##](https://www.codedex.io/projects/generate-a-blog-with-openai#python-file) Archivo Python

Ahora que tenemos nuestro conjunto de variables de entorno, abramos el **blog\_generador.py** archiva y pega este c√≥digo debajo `import openai`.

    from dotenv import dotenv_values
    
    config = dotenv_values(".env")
    

Primero, hemos importado un m√©todo llamado `dotenv_values` del m√≥dulo.

El `dotenv_values()` tomar√° el camino hacia el **.env** archiva y devu√©lvanos un diccionario con todas las variables en el **.env** archivo. Luego creamos un `config` variable para mantener ese diccionario.

Ahora, todo lo que tenemos que hacer es reemplazar la clave API expuesta con la variable de entorno en el `config` diccionario como as√≠:

    openai.api_key = config['API_KEY']
    

¬°Eso es todo! Nuestra clave API ahora est√° segura y oculta del c√≥digo principal.

**Nota**: Si desea enviar su c√≥digo a [GitHub](https://www.github.com/), no quieres empujar el **.env** archivo tambi√©n. En el directorio ra√≠z de su proyecto, cree un archivo llamado **.gitignore**, y en el archivo Git ignore, escriba `.env`. Esto evitar√° que el archivo sea rastreado por Git y finalmente empujado a GitHub.

¬°Con todo ese set y hecho, weizre terminado! ¬°El c√≥digo ahora deber√≠a verse as√≠!

**blog\_generador.py** archivo:

    # Generate a Blog with OpenAI üìù
    
    import openai
    from dotenv import dotenv_values
    
    config = dotenv_values('.env')
    
    openai.api_key = config['API_KEY']
    
    def generate_blog(paragraph_topic):
      response = openai.completions.create(
        model = 'gpt-3.5-turbo-instruct',
        prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,
        max_tokens = 400,
        temperature = 0.3
      )
      retrieve_blog = response.choices[0].text
      return retrieve_blog
    
    keep_writing = True
    
    while keep_writing:
      answer = input('Write a paragraph? Y for yes, anything else for no. ')
      if (answer == 'Y'):
        paragraph_topic = input('What should this paragraph talk about? ')
        print(generate_blog(paragraph_topic))
      else:
        keep_writing = False
    

**.env** archivo:

    API_KEY=sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk
    

## [#](https://www.codedex.io/projects/generate-a-blog-with-openai#finish-line) L√≠nea de Acabado

¬°Felicidades, acabas de crear un generador de blogs con OpenAI y Python! A lo largo del proyecto, aprendimos c√≥mo usar GPT-3 para generar un p√°rrafo, usar un `while` bucle para crear m√∫ltiples p√°rrafos y proteger nuestra aplicaci√≥n con un **.env** archivo. üôå

La IA se est√° expandiendo r√°pidamente, y los primeros en utilizarla adecuadamente a trav√©s de servicios como GPT-3 se convertir√°n en los inovadores en el campo. Espero que este proyecto te ayude a entenderlo un poco m√°s.

¬°Y por √∫ltimo, nos encantar√≠a ver lo que construyes con este tutorial! Etiqueta [@codedex\_io](https://twitter.com/intent/tweet?text=Generate+a+Blog+with+OpenAI&hashtags=Python&hashtags=Codedex+@codedex_io) y [@openai](https://twitter.com/openai) ¬°en Twitter si haces algo genial!



